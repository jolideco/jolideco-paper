% Define document class
\documentclass[twocolumn]{aastex631}

% Filler text
\usepackage{blindtext}
\usepackage{amsmath}
\usepackage[utf8]{inputenc}
\usepackage{showyourwork}
\usepackage{amssymb}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator{\arcsinh}{arcsinh}
\newcommand{\chandra}{\textit{Chandra}~}
\newcommand{\xmm}{\textit{XMM}~}
\newcommand{\fermi}{\textit{Fermi}-LAT~}
\newcommand{\jolideco}{\textit{Jolideco}~}
\newcommand{\todo}[1]{\textcolor{red}{TODO: #1}\PackageWarning{TODO:}{#1!}}

\newcommand{\vlk}[1]{{\color{blue} [VLK: #1]}}

% Begin!
\begin{document}

% Title
    \title{\jolideco: Joint Likelihood Deconvolution of Astronomical Images in the Presence of Poisson Noise}

% Author list
    \author[0000-0003-4568-7005]{Axel Donath}
    \author[0000-0002-0905-7375]{Aneta Siemiginowska}
    \author[0000-0002-3869-7996]{Vinay Kashyap}
    \author[0000-0000-0000-0000]{David van Dyk}


% Abstract with filler text
    \begin{abstract}
        We present a new method for (Jo)int (li)kelihood  (Deco)nvolution (\jolideco) of a set of astronomical observations of the same sky region in the presence of Poisson noise.
        The method reconstructs an image from a set of observations
        by optimizing the a-posteriori joint Poisson likelihood of all
        observations under an patch based image prior. The patch
        prior is parameterised by a standard Gaussian Mixture model (GMM)
        learned from astronomical images at other wavelenghts and
        adapted to the structures expected to see in the image.
        By applying the method to simulated data we show that
        the combination of mutiple observations leads to an
        improved reconstruction quality in the regime with S/N ratio of.
        We show also that the method yields superior reconstruction quality
        to alternative standard methods such as the Richardson-Lucy method.
    \end{abstract}

    % Main body with filler text


    \section{Introduction}
    The quality of all astronomical images is affected by the limited angular resolution of the instrument
    or telescope. In addition the images are affected by the presence of noise and non-uniform exposure.

    In literature there have been multiple efforts to correct the degrading of the images
    and maximise the scientific use. 
    
    Any astronomical observation is affected by the limited angular resolution of the telescope. However the problem is not specific to astronomy and has been tried to 
    be solved for fluoresence image or others...

    \begin{itemize}
        \item Standard baseline method is Richardson \& Lucy (RL), see \cite{Richardson1972} and \cite{Lucy1974}
        \item Joint likelihood RL: \cite{Ingaramo2014} has found that RL take the best out of each image and create a "merged" image
        \item  Problem of RL decomposing structures into point sources: \cite{Reeves1994} \cite{Fish1995}
        \item Multi-scale LIRA prior of course: \cite{Esch2004, Connors2011}, advantage of error estimates / Bayesian sampling. However prior is rather "ad-hoc", no physical information / assumptions. Just "smoothness"
        \item What abput d3po and d4po? Priors based on physical assumptions, decomposition into point and diffuse flux, but in 3d/4d \cite{Selig2015}\cite{Pumpe2018}
    \end{itemize}
    
    
    % \begin{figure*}
    %     \script{rl_decomposition.py}
    %     \begin{centering}
    %         \includegraphics[width=\textwidth]{figures/richardson-lucy-decomposition.pdf}
    %         \caption{
    %             Decomposition of the RL algorithm for various number of iterations. \todo{Improve figure}
    %         }
    %         \label{fig:rl_decomposition}
    %     \end{centering}
    % \end{figure*}

    \subsection{A note on Deep Learning Methods}
    \cite{Li2014} have introduced a baseline architecture for a deep convolutional neural network for image deblurring.
    The convolutional nature of the network does not make it suitable for the task. As convolution introduces smoothing.
    However the network can learn an "inverse kernel", which needs to be larger because of the uncertainty principle (\todo{reference...}).
    The large kernels are introduced by separability assumption...
    In the limit of Poisson noise it is desirable to trace the full a-postiori likelihood, which is not possibly for most network architectures. Except for e.g. normalising flows \todo{there are refences where NFs have bee used as priors...}

    \section{Method}
    \subsection{Poisson Joint Likelihood}
    Our goal is to recover an image $\mathbf{x}$ from a set of multiple
    low counts observations.
    Most generally we assume our total dataset consists of $J$ individual
    observations of the same region of the sky, which are jointly
    modelled. The assumption is that the underlying \textit{true} emission image,
    we are looking for does not change with time. Under this assumption these
    datasets can be for example:

    \begin{itemize}
        \item Different observations of one instrument or telescope at different times and observation conditions. E.g., multiple observations of \chandra with different offset angles and exposure times.
        \item Observations of different telescopes, which operate in the same wavelength range. E.g., a \chandra
        and \xmm observation of the same region in the sky.
        \item A single observation of one telescope with different data quality categories and different associated instrument
        response functions. E.g., event classes for \fermi.
    \end{itemize}

    Or even an arbitrary combination of the possibilities listed above.

    For each individual observation $j$ the predicted counts can be modelled by forward
    folding the unknown flux image $\mathbf{x}$ with the individual (per observation) instrument response:

    \begin{equation}
        \label{eq:model}
        \boldsymbol{\lambda}_j = \mathrm{PSF}_j \circledast \left(\mathbf{E}_j \cdot (\mathbf{x} + \mathbf{B}_j) \right)
    \end{equation}

    Where the expected counts $\lambda_j$ are given by the convolution of the unknown 
    flux image $\mathbf{x}$ with the observation specific point spread function $\mathrm{PSF}_j$. Additionally
    an observation specific image of the exposure $\mathbf{E}_j$ and background emission $\mathbf{B_j}$ can be
    optionally taken into account.

    Given a single observation $j$ of an unknown flux image
    $\mathbf{x}$ and assuming the noise in each pixel $i$ in the recorded counts image
    $\mathbf{D_j}$ follows a Poisson distribution, the likelihood $\mathcal{P}$
    of obtaining the measured image from a model image of the expected
    counts $\boldsymbol{\lambda_j}$ with $N$ pixels is given by:

    \begin{equation}
        \label{eq:poisson}
        \mathcal{P}\left( \mathbf{D_j} | \boldsymbol{\lambda_j} \right) = \prod_{i=1}^N \frac{{e^{ - D_{j,i} } \lambda_i ^ {D_{j,i}}}}{{D_{j,i}!}}
    \end{equation}

    By taking the logarithm and dropping the constant terms one can transform the
    product into a sum over pixels, which is also often called the \textit{Cash}
    \citep{Cash1979} fit statistics:

    \begin{equation}
        \label{eq:cash}
        \mathcal{C}\left( \mathbf{D_j} | \boldsymbol{\lambda_j} \right) = \sum_{i=1}^N \lambda_{j,i} - D_{j, i} \log{\lambda_{j,i}}
    \end{equation}

    By summing over all observations we finally get the joint log-likelihood of measuring a set of counts images $\mathbf{D}$ given an unknown flux image $\mathbf{x}$:

    \begin{equation}
        \label{eq:joint}
        \mathcal{L}\left( \mathbf{D} | \mathbf{x} \right) = \sum_{j=1}^J \mathcal{C}\left( \mathbf{D_j} | \mathbf{x} \right)
    \end{equation}

    Using Maximum Likelihood Estimation (MLE) we could try to estimate $\mathbf{x}$ directly,
    using some minimization procedure. However in general this represents an \textit{ill posed}
    inverse problem. Solutions for $\mathbf{x}$ which yield similar likelihood values $\mathcal{L}_{\mathrm{Joint}}(\hat{\mathbf{x}})$ look very different from each other and might also look different compared to a 
    given ground truth, if available. Both the convolution operation as well as the level of noise lead
    to a loss of information in the data which cannot easily be recovered. 
    
    \todo{this sum corresponds to the loop over datasets in machine learning... }

    \subsection{A Posterirori Joint Likelihood}
    When reconstructing images in the context of inverse problems we are operating
    in a high dimensional parameter space, because each pixel represents
    an independent parameter in the optimization process. By using prior information
    we can introduce correlation between the parameters, reduce the \textit{effective}
    dimensionality of the problem and guide the optimization process towards unique 
    and more stable solutions.
    
    Using Bayes rule we can estimate the a posteriori likelihood under a given prior instead:

    \begin{equation}
        \label{eq:bayes}
        \mathcal{P}(\mathbf{x}|\textbf{D}) = \mathcal{P}(\mathbf{x} ) \frac{\mathcal{P}(\textbf{D} |\mathbf{x})}{ \mathcal{P} (\textbf{D})}
    \end{equation}

    And use a Maximum a Posteriori (MAP) approach to find an estimate for $\mathbf{x}$.
    Taking the logarithm of Eq.~\ref{eq:bayes}, replacing the definition of the likelihood $\mathcal{P}(\mathbf{D}|\mathbf{x})$ with Eq.~\ref{eq:joint} and dropping the term $\mathcal{P}(\mathbf{D})$
    which is independent of $\mathbf{x}$, we get the following expression for the log-posterior
    likelihood $\mathcal{L}$ :
    
    \begin{equation}
        \label{eq:total}
        \mathcal{L}\left(\mathbf{x} | \mathbf{D} \right) = \sum_m^M \mathcal{C}\left( \mathbf{D_m} | \mathbf{x} \right) - \beta \cdot \mathcal{L}(\mathbf{x})
    \end{equation}

    Where $\mathcal{C}\left( \mathbf{D_j} | \mathbf{x} \right)$ represents the summed log-likelihood
    for an individual observation $j$. Additionally the function includes a prior term $\mathcal{P}(\mathbf{x})$
    and a factor $\beta$ to adjust the weight of the prior with respect to the data likelihood term.

    \subsection{Patch Based Priors}
    In general it is difficult to capture global image statistics in a prior likelihood
    taking into account all pixel to pixel correlations. The size of the corresponding
    correlation matrix would grow with the number of pixels squared. However
    astronomical images typically show local correlations between pixels.
    This means on smaller scales images often contain basic structure such as 
    edges, corners, periodic patterns or small regions of constant brightness.

    \cite{Zoran2011} build on this assumption for natural images and introduced the approach of
    learning local image statistics based on patch priors. Their main idea
    was to learn the statistics of natural images on a small
    spatial scales instead. For this they proposed to split images from a
    representative prior dataset into small patches of size 8x8~pixels.
    Then they learned a 64 dimensional Gaussian Mixture Model (GMM) on the
    extracted patches, treating each pixel as an independent dimension in
    the model, with $k=200$ Gaussian components. They showed that the patch based GMM
    prior led to much improved image reconstructions for multiple inverse problems 
    such as denoising, deblurring and inpainting.
    
    One of the main advantages of the GMM is the possibility to evaluate its log-likelihood
    in closed form. It is given by:

    \begin{equation}
        \ell_{GMM}(\theta) = \sum_{i=1}^n \log \left( \sum_{k=1}^K \pi_k N(x_i;\mu_k, \Sigma_k^2) \right )
    \end{equation}

    Mean value is subtracted, which represents the assumption that image structure is independent
    of the pixel amplitude.
    With parameters $\theta = \{\mu_1,\ldots,\mu_K,\sigma_1,\ldots,\sigma_K,\pi_1,\ldots,\pi_K\}$.
    To use the learned GMM as prior for the reconstruction of another image, the image is split into
    overlapping patches. For each of the patches the log-likelihood for each of the GMM components is
    evaluated. The resulting grid of overlapping patches is illustrated in Figure~\ref{fig:patches}.

    For each 8x8 pixel patch the likelihood of all components of the GMM is evaluated. Then 
    \begin{equation}
        \hat{k} = \argmax{\ell_{GMM}(\theta)}
    \end{equation}

    The argmax is needed because of the locality...

    \begin{equation}
        \mathcal{P}(x) = \sum_n \log{p_{\hat{k}}(\mathbf{P}_n x)}
    \end{equation}

    $\mathbf{P}_n$ is a matrix that extracts the $n$-th patch
    from the image $\mathbf{x}$ to be reconstructed.
    $p(\mathbf{P}_n x)$ is the probability of that patch
    under the GMM.


    \begin{figure}[ht!]
        \script{patches.py}
        \begin{centering}
            \includegraphics[width=\linewidth]{figures/patches.pdf}
            \caption{
                Grid of overlapping patches of size 8x8 pixels. The overlap size was chosen to be 2 pixels.
            }
            \label{fig:patches}
        \end{centering}
    \end{figure}

    \cite{Bouman2016} later adapted the patch prior reconstruction to be used
    with radio astronomy data.
    They have shown that the reconstructed image only weakly depends on the choice
    of the reference data on which the the patch prior is learned. They found
    equivalent results for GMMs learned on natural images and specifically
    simulated images of black hole ring structures.

    \subsubsection{Image Normalisation and Dynamic Range}
    Astronomical images typically show a much higher dynamic range compared to 
    natural images. This is mostly due to the existence of point sources, which
    rarely occur in natural images. Astronomical point sources typically relate
    to compact bright objects, such as active galactic nuclei at high distances,
    or binary objects and stars at Galactic distances.
    
    The high dynamic range of astronomical images challenges any deconvolution method.
    To recover point sources accurately it is required to keep correlations with
    neighbouring pixels low, while for extended source the opposite is true. Ideally
    those contradicting requirements can be handled with a flexible prior assumption,
    which adapts to the data, such as the patch based GMM prior.
    
    The GMM patch prior is learned from other images whose pixel intensities
    have no physical relationship of the intensities of the Poisson data we are
    dealing with. Thus the GMM is learned on normalized images, where the intensity values
    are constrained between 0 and 1. To evaluate the GMM patch prior on the 
    model image $\mathbf{x}$ the pixel values of $\mathbf{x}$  need to be mapped 
    in the same dynamic range between 0 and 1. Multiple common choices for such a
    mapping function are shown in Fig.~\ref{fig:image-norms}. 

    \begin{figure}[ht!]
        \script{image-norms.py}
        \begin{centering}
            \includegraphics[width=\linewidth]{figures/image-norms.pdf}
            \caption{
                Various image norms with different dynamic behaviour.
            }
            \label{fig:image-norms}
        \end{centering}
    \end{figure}

    The choice of the image normalisation allows to adjust the contrast of the image
    and e.g. enhance low intensity structures, which also enhances the regularising
    effect of the patch prior. 

    \todo{Which normalisation to choose, atan, asinh, log, inverse-cdf?}

    There are arguments for $\arcsinh(\mathbf{x})$, see e.g. \cite{Lupton2004}.

    \subsubsection{Cycle Spinning}
    To avoid artifact due to the choice of the grid of overlapping patches we propose
    three variations:

    \begin{itemize}
        \item Cycle spinning by randomly shifting the image by a given number of pixels in x and y direction, e.g. used in \cite{Esch2004}
        \item Sub pixel cycle spinning, by randomly distributing the brightness of a given pixel to a 4 pixel grid \todo{This is something I came up with to allow for point sources to have sub-pixel positions, but I never showed it actually works...}
        \item A randomly chosen patch grid, such that each pixel is at least covered once.
        The random grid of patches was proposed by \cite{Parameswaran2018}. This has the advantage of potentially speeding up the computation as well.
    \end{itemize}

    \subsection{Cross Validation}
    Cross validation (CV) is an established method for model selection in statistics
    and machine learning to prevent over-fitting the data. To perform CV the available
    data is slit into a "training" and "validation" dataset. While optimizing the
    log-likelihood value is monitored 
    
    The use of multiple dataset allows to use cross-validation to prevent overfitting.
    One of the standard techniques in "machine learning"...

    Cross validation is feasible once sufficient data is available, which is e.g. the 
    case for deep \chandra~observations.

    CV as stopping rule for RL was proposed by \cite{Reeves1995}...

    \subsection{Systematic Errors of Predicted Counts}
    Each measured counts image $\mathbf{D_j}$ is associated with systematic errors.
    This includes e.g. the absolute position of the sources in the image (astrometry) and the normalisation of the background model, which can vary between observations.
    To account for this we extend the model for the predicted
    counts introduced in Eq.~\ref{eq:model}, by a background normalisation factor
    $\alpha_j$ and a linear shift in position $\phi_j(\mathbf{x}| \delta_{x,j}, \delta_{y,j})$,
    which is specific for each observation. This yields the following modified model definition:
    
    \begin{equation}
        \label{eq:model-npred-calibration}
        \mathbf{\lambda}_j = \mathrm{PSF}_j \circledast \left(\mathbf{E}_j \cdot (\phi_j(\mathbf{x}| \delta_{x,j}, \delta_{y,j}) + \alpha_j \cdot \mathbf{B}_j) \right)
    \end{equation}
    
    In practice one observation is used as a reference and its corresponding
    systematic shifts in position $\delta_{x,j}, \delta_{y,j}$ are frozen during
    optimization. An example of the effect of the positional shift and background
    normalisation can be seen in Fig.~\ref{fig:npred-systematics}.

    \subsubsection{Statistical Errors}
    \begin{itemize}
        \item Bootstrapping observations
        \item Bootstrapping events
        \item Hessian diagonal
    \end{itemize}
    
    \section{Implementation}
    \subsection{Jolideco Framework}
    The goal of the reconstruction process is to optimize the a-posteriori
    likelihood defined by Equation~\ref{eq:total}. Given that each pixel
    in the reconstructed image represents an independent parameter
    this represents a high dimensional optimization problem.
    Differentiable programming frameworks such as \texttt{PyTorch}~\citep{Pytorch2019}
    allow for solving these kind of high dimensional modeling problems, by using
    back-propagation and adapted optimization methods for high dimensional
    models such as stochastic gradient decent.

    We implemented the \jolideco method as an independent Python package, 
    based on \texttt{PyTorch} as optimization back-end. We tried to define a modular,
    object oriented code structure, to allow parts of the algorithm to be
    flexible and interchangeable, such as choice of image normalisation scales,
    the choice of GMM models, optimization methods and serialisation formats for the 
    reconstruction results as well as corresponding diagnostic information
    such as the trace of the posterior and prior and likelihood values.
    The package is available at \url{https://github.com/jolideco/jolideco}

    We also use \texttt{Numpy}~\citep{Numpy2020} for handling data arrays and
    \texttt{Matplotlib}~\citep{Hunter2007} for plotting.
    To learn the Gaussian Mixture Models from patches we the standard implementation
    provided in the \texttt{Scikit-Learn}~\citep{Skimage2014} package. To handle the 
    serialisation of images to the FITS data format and to handle world coordinate
    systems (WCS) we use \texttt{Astropy}~\citep{Astropy2018}.
    For optimization and internal data handling we use \texttt{PyTorch}.

    \subsection{Jolideco GMM Library}
    On radio data \cite{Bouman2016} found the results to be mostly independent 
    of the choice of data the GMM prior was learned on. In the low counts and high
    noise regime we expect a much higher dependence of the results on choice of the
    data the GMM was learned on. For testing we learned and provide a selection of GMMs to be used with the patch prior for download \footnote{\url{https://github.com/jolideco/jolideco-gmm-library}}.
    
    \subsubsection{Zoran \& Weiss}
    As baseline reference GMM we use the original model provided by \cite{Zoran2011}. The model was learned
    from the Berkley image database, by splitting the images into 8x8 patches. 
    It was downloaded from \url{https://people.csail.mit.edu/danielzoran/epllcode.zip}.
    
    \subsubsection{GLEAM Radio Data}
    A prior learned from astronomical data for analysis of Galactic sources with 
    rich morphology, such as supernova remnants, pulsar winds etc.
    High signal to noise Radio data from \cite{HurleyWalker2022}.
    There is physical correlation between e.g. the very high energy gamma range
    and radio as emission is produced from the same electron populations.
    We download 

    \subsubsection{NRAO Jets, Jets, Jets}
    For the specific application of jet detection in extract galactic data we we learned a GMM patch prior from jet images. It encodes the prior knowledge of the preferred direction of the jet. 

    \begin{itemize}
        \item One with horizontal direction, where the image to be analysed should be rotated. E.g. if prior knowledge from radio data is available.
        \item One with randomised direction, if now prior knowledge is available.
    \end{itemize}
    

    \subsection{Computational Performance}
    We conduct as as series of performance benchmarks (see Appendix?) to asses the scalability of the method to a large number of observations
    as well as large images. 

    \begin{itemize}
        \item Results are available in \url{https://github.com/jolideco/jolideco-benchmarks}
        \item we tried the binary search tree as proposed in \cite{Parameswaran2018},
        but without success, most likely because the native \texttt{Pytorch} support
        for parallelisation speeds up the standard GMM quite a bit...
        \item Could use a Neural Net for GMM component selection as proposed in
        \item GPU support via \texttt{Pytorch}

    \end{itemize}

    \subsection{Optimization Strategy}
    In practice we employ the following optimization strategy:
    \begin{itemize}
        \item the optimizer sees $\log{\mathbf{x}}$
        \item First run with uniform prior, to get a rough estimate
        \item Then optimize the parameters associated to the systematic error described in Eq.~\ref{eq:model-npred-calibration}.
        \item Then we go for a full optimization using the patch prior, which can be computationally costly
        \item we use ADAM (stochastic gradient decent), without decay
        \item learning rate scheduling? So far just a fixed step size value of $1e-3$
    \end{itemize}
    
    
        
    \section{Experiments}
    \subsection{Test Datasets}
    \todo{Vinay writes this?}
    \vlk{yes}

    \vlk{We have devised four distinct arrangements of combinations of point and extended sources of differents shapes to test the algorithms.  The arrangements are 
    \begin{itemize}
        \item[ ``Gauss":] A set of four point sources arranged around an extended Gaussian source
        \item[``Points":] Point sources arranged with different separations
        \item[``Shield":] Disk shaped flat extended source with superposed point sources and linear jet-like features
        \item[``Spiral":] Extended thin double-spiral with a flat disk at the center and point sources adjacent to it
    \end{itemize}
    The arrangements are shown in Figure~TBD, and the details of the locations and brightness of each component is listed in Table~TBD.
    }

    We use the test datasets provided by Vinay et al.
    First we evaluate the performance of the method on a set of simulated observations.
    For this we assume:

    \begin{itemize}
        \item An instrument with good angular resolution, but low effective area (e.g. like Chandra)
        \item An instrument with worse angularr resolution, bur higher effective area (e.g. like XMM)
    \end{itemize}

    For both scenarios we assume a Gaussian PSF of sizes $\sigma = 2$ pixels and  $\sigma = 5$.
    As true flux we consider the following scenarios:

    \begin{itemize}
        \item Point source with varying distances and brightness
        \item Disk and point sources of varying brightness
        \item Spiral and point sources of varying brightness
    \end{itemize}

    Background levels of $\lambda_{Bkg}= 0.001, 0.01 \textrm{and} 0.1 \textrm{counts/pixel}$. 
    
    Show results of experiments on simulated toy datasets

    

    \subsection{Results}

    The package is available at \url{https://github.com/jolideco/jolideco-comparison}


    \section{Application Examples}
    Show results from real observations

    \subsection{Deep \chandra Observation}
    \begin{figure*}[ht!]
        \script{example-chandra.py}
        \begin{centering}
            \includegraphics[width=\linewidth]{figures/example-chandra.pdf}
            \caption{
                Chandra Example
            }
            \label{fig:example-chandra}
        \end{centering}
    \end{figure*}

    \subsection{Combined \xmm and \chandra Observation}
    \begin{figure*}[ht!]
        \script{example-xmm-chandra.py}
        \begin{centering}
            \includegraphics[width=\linewidth]{figures/example-xmm-chandra.pdf}
            \caption{
                Chandra Example
            }
            \label{fig:example-xmm-chandra}
        \end{centering}
    \end{figure*}


    \subsection{\fermi Event Classes}
    \begin{figure*}[ht!]
        \script{example-fermi-lat.py}
        \begin{centering}
            \includegraphics[width=\linewidth]{figures/example-fermi-lat.pdf}
            \caption{
                Chandra Example
            }
            \label{fig:example-fermi-lat}
        \end{centering}
    \end{figure*}

    \section{Reproducibility}

    The paper is available at \url{https://github.com/jolideco/jolideco-paper} and can be reproduced using \cite{Luger2021}.
    
    


    \section{Summary \& Conclusions}
    In this work we presented a new method for image deconvolution and denoising in the presence of Poisoon noise.
    Jolideco is great...

    \begin{itemize}
        \item Extend \jolideco to handle spectral dimension at the same time.
        \item Use normalising flows for patch priors see e.g. https://arxiv.org/abs/2205.12021
        \item 
    \end{itemize}
    

    \section*{Acknowledgements}
    This work was conducted under the auspices of the CHASC International Astrostatistics Center.
    CHASC is supported by NSF grants DMS-21-13615, DMS-21-13397, and DMS-21-13605; by the UK Engineering
    and Physical Sciences Research Council [EP/W015080/1]; and by NASA 18-APRA18-0019.
    We thank CHASC members for many helpful discussions, especially Xiao-Li Meng and Katy McKeough.
    DvD was also supported in part by a Marie-Skodowska-Curie RISE Grant (H2020-MSCA-RISE-2019-873089)
    provided by the European Commission.
    Aneta Siemiginowska, Vinay Kashyap, and Doug Burke further acknowledge support from NASA
    contract to the Chandra X-ray Center NAS8-03060.

    \newpage
    \bibliography{bib.bib}
\end{document}
